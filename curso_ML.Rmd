---
title: "Curso_ML"
author: "Irene Mendoza"
date: '2022-04-21'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### Notas del curso

## Curso de Machine Learning impartido por Javier García Algarra

Importar en Orange: CSV file import
Aparecen las características del fichero.
Data table: sirve para ver la estructura del . Hay que darle unos datos como entrada. 

Lo normal es que haya 90/10 de casos diferentes para sí/no.
Splilt by para dividir variables. Solo para variables categóricas.

Select column para elegir las variables a meter en el mdoelo. 
Se colocan las variables que se quieren ignorar en el modelo usando select column.    

Target: variable que queremos predecir.
poutcome se elimina porque afecta al resultado. 

Tenemos que separar los datos en dos conjuntos: el training y el testing. Normalmente se deja el 80 para el training y el 20 para el testing. 

Se usa data sampler para separar en dos partes el conjunto de datos.

Se puede elegir un modelo estratificado. 

Deterministic sampling: hay que mantener el orden de la separación.

Para quedarnos con el 30% tengo que poner en el enlace "remaining data".

Hay que elegir el modelo a escoger

Usamos una regresión logística: se elige el modelo.

Tiempo de regularización: hiperparámetro. Ridge es el que se elige. Es un tipo de regularización (ver libro).

Para ver el resultado, hay que crear una nueva cajita que se llama "test and scoring": se les conecta el modelo logístico, el training set y el testing set.

Seleccionar el modelo sobre "test data". Me sale una AUC sobre 0.87.

Para ver el área under the curve, tengo que ir a test and scoring.

Probamos ahora con un *random forest*. Enchufo la salida con los datos de entrenamiento y la salida, con test and score. 

El tree es mucho peor modelo. 

Random forest, casi igual que la regresión logística. POdemos cambiar el número de árboles. 

Gradient boosting. Saca una AUC parecida al resto. 

Las redes neuronales es el único modelo que metiendo más capas, no produce overfitting..

El overfitting se ve cuando baja la AUC a medida que se añaden más parámetros. 

Cómo sabemos las variables que tienen más peso. ¿Dónde están los coeficientes de cada variable? Para verlo, añado un data table y lo conecto a la salida de logistic regression

Hay que ver antes si las variables están correlacionadas: se usa una caja que se llama Rank. Lo enchufamos a seleccionar columnas. Vemos cuánto contribuye cada llamada a la contratación del seguro.  La duración de la llamada es una consecuencia de la contratación del seguro. "Duration" no sirve para hacer el predictor. Se quita usando "ignore" columns.   

Create instance, para meter a mano los datos de un caso. Muestreo una entrada elegida que sirve como patrón. Se une la cajita predictions y se le conectan los datos de entrada y el modelo que quiero predecir. 

Se puede enchufar directamente el logistic regression a selected columns y luego poner la validación cruzada. En la realidad, en lugar de separar 80 y 20, y se separan los datos en dos subconjuntos. 


## Boston price ##

La variable respuesta es medv
mv es el número de habitaciones de la vivienda

Como hay pocos casos, con data sampler, se separa 20 y 80.
Marcar siempre "test on test data". 
Se usa el R2, coeficiente de determinación.

Cuanto más cercano sea a 1, el modelo es mucho mejor. 

El que mejor funciona es el gboost.

Con Orange data mining se pueden hacer modelos no supervisados y de reconocimiento de imagen. 

Para el próximo día, hacen falta ejemplos que están en la web

Razonamiento simbólico asociado a las redes neuronales. 

```{r cars}
summary(cars)
```

